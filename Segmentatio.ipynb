{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.ndimage.morphology import binary_erosion, binary_fill_holes\n",
    "\n",
    "# Functions\n",
    "def hu_to_grayscale(volume):\n",
    "    volume = np.clip(volume, -512, 512)\n",
    "    mxval  = np.max(volume)\n",
    "    mnval  = np.min(volume)\n",
    "    im_volume = (volume - mnval)/max(mxval - mnval, 1e-3)\n",
    "    im_volume = im_volume\n",
    "    return im_volume *255\n",
    "\n",
    "def get_mask_alung(vol):\n",
    "    vol_im = np.where(vol>0, 1, 0)\n",
    "    shp    = vol.shape\n",
    "    around_lung = np.zeros((shp[0], shp[1], shp[2]), dtype=np.float32)\n",
    "    for idx in range(shp[0]):\n",
    "            around_lung[idx, :, :] = binary_erosion(vol_im[idx], structure=np.ones((15,15))).astype(vol_im.dtype)\n",
    "            \n",
    "    return around_lung\n",
    "\n",
    "def get_mask(segmentation):\n",
    "    # initialize output to zeros\n",
    "    shp    = segmentation.shape\n",
    "    lung = np.zeros((shp[0], shp[1], shp[2]), dtype=np.float32)\n",
    "   \n",
    "    # Get mask for kidney and tumor\n",
    "    lung[np.equal(segmentation,255)] = 255\n",
    "    \n",
    "    return lung\n",
    "    \n",
    "def get_FOV(around_lung, lung):\n",
    "    FOV = np.where((around_lung + lung) >0, 1, 0)\n",
    "    for idx in range(FOV.shape[0]):\n",
    "        FOV[idx, :, :] = binary_fill_holes(FOV[idx, :, :], structure=np.ones((5,5))).astype(FOV.dtype)\n",
    "    return FOV\n",
    "\n",
    "def return_axials(vol, seg):\n",
    "\n",
    "    # Prepare segmentation and volume\n",
    "    vol = vol.get_data()\n",
    "    seg = seg.get_data()\n",
    "    seg = seg.astype(np.int32)\n",
    "    \n",
    "    # Convert to a visual format\n",
    "    vol_ims = hu_to_grayscale(vol)\n",
    "    lung    = get_mask(seg)\n",
    "    around_lung = get_mask_alung(vol_ims)\n",
    "    FOV = get_FOV(around_lung, lung)\n",
    "    around_lung = np.where((FOV - lung) >0, 1, 0)\n",
    "\n",
    "    return vol_ims, lung, around_lung, FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "\n",
    "def BCDU_net_D3(input_size = (256,256,1)):\n",
    "    N = input_size[0]\n",
    "    inputs = Input(input_size) \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    # D1\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
    "    conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4_1 = Dropout(0.5)(conv4_1)\n",
    "    # D2\n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4_1)     \n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_2)\n",
    "    conv4_2 = Dropout(0.5)(conv4_2)\n",
    "    # D3\n",
    "    merge_dense = concatenate([conv4_2,drop4_1], axis = 3)\n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_dense)     \n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_3)\n",
    "    drop4_3 = Dropout(0.5)(conv4_3)\n",
    "    \n",
    "    up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(drop4_3)\n",
    "    up6 = BatchNormalization(axis=3)(up6)\n",
    "    up6 = Activation('relu')(up6)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
    "    merge6  = concatenate([x1,x2], axis = 1) \n",
    "    merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge6)\n",
    "            \n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
    "    up7 = BatchNormalization(axis=3)(up7)\n",
    "    up7 = Activation('relu')(up7)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
    "    merge7  = concatenate([x1,x2], axis = 1) \n",
    "    merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
    "        \n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
    "    up8 = BatchNormalization(axis=3)(up8)\n",
    "    up8 = Activation('relu')(up8)    \n",
    "\n",
    "    x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
    "    x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
    "    merge8  = concatenate([x1,x2], axis = 1) \n",
    "    merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
    "    \n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
    "\n",
    "    model = Model(inputs, conv9)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "    return model\n",
    "\n",
    "def BCDU_net_D1(input_size = (256,256,1)):\n",
    "    N = input_size[0]\n",
    "    inputs = Input(input_size) \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    # D1\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
    "    conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4_1 = Dropout(0.5)(conv4_1)\n",
    "   \n",
    "    up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv4_1)\n",
    "    up6 = BatchNormalization(axis=3)(up6)\n",
    "    up6 = Activation('relu')(up6)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
    "    merge6  = concatenate([x1,x2], axis = 1) \n",
    "    merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge6)\n",
    "            \n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
    "    up7 = BatchNormalization(axis=3)(up7)\n",
    "    up7 = Activation('relu')(up7)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
    "    merge7  = concatenate([x1,x2], axis = 1) \n",
    "    merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
    "        \n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
    "    up8 = BatchNormalization(axis=3)(up8)\n",
    "    up8 = Activation('relu')(up8)    \n",
    "\n",
    "    x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
    "    x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
    "    merge8  = concatenate([x1,x2], axis = 1) \n",
    "    merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
    "    \n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
    "\n",
    "    model = Model(inputs, conv9)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyModels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16056\\1662104361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPyModels\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PyModels'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import models as M\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.ndimage.morphology import binary_erosion\n",
    "\n",
    "####################################  Load Data #####################################\n",
    "folder    = './processed_data/'\n",
    "te_data   = np.load(folder+'data_test.npy')\n",
    "FOV       = np.load(folder+'FOV_te.npy')\n",
    "te_mask   = np.load(folder+'mask_test.npy')\n",
    "\n",
    "te_data  = np.expand_dims(te_data, axis=3)\n",
    "\n",
    "print('Dataset loaded')\n",
    "#te_data2  = dataset_normalized(te_data)\n",
    "te_data2 = te_data /255.\n",
    "model = M.BCDU_net_D3(input_size = (512,512,1))\n",
    "model.summary()\n",
    "model.load_weights('weight_lung')\n",
    "predictions = model.predict(te_data2, batch_size=2, verbose=1)\n",
    "\n",
    "# Post-processing\n",
    "predictions = np.squeeze(predictions)\n",
    "predictions = np.where(predictions>0.5, 1, 0)\n",
    "Estimated_lung = np.where((FOV - predictions)>0.5, 1, 0)\n",
    "\n",
    "# Performance checking\n",
    "\n",
    "y_scores = Estimated_lung.reshape(Estimated_lung.shape[0]*Estimated_lung.shape[1]*Estimated_lung.shape[2], 1)\n",
    "print(y_scores.shape)\n",
    "\n",
    "y_true = te_mask.reshape(te_mask.shape[0]*te_mask.shape[1]*te_mask.shape[2], 1)\n",
    "\n",
    "y_scores = np.where(y_scores>0.5, 1, 0)\n",
    "y_true   = np.where(y_true>0.5, 1, 0)\n",
    "\n",
    "output_folder = 'output/'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "#Area under the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve((y_true), y_scores)\n",
    "AUC_ROC = roc_auc_score(y_true, y_scores)\n",
    "print (\"\\nArea under the ROC curve: \" +str(AUC_ROC))\n",
    "roc_curve =plt.figure()\n",
    "plt.plot(fpr,tpr,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_ROC)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel(\"FPR (False Positive Rate)\")\n",
    "plt.ylabel(\"TPR (True Positive Rate)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(output_folder+\"ROC.png\")\n",
    "\n",
    "#Precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "precision = np.fliplr([precision])[0] \n",
    "recall = np.fliplr([recall])[0]\n",
    "AUC_prec_rec = np.trapz(precision,recall)\n",
    "print (\"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec))\n",
    "prec_rec_curve = plt.figure()\n",
    "plt.plot(recall,precision,'-',label='Area Under the Curve (AUC = %0.4f)' % AUC_prec_rec)\n",
    "plt.title('Precision - Recall curve')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(output_folder+\"Precision_recall.png\")\n",
    "\n",
    "#Confusion matrix\n",
    "threshold_confusion = 0.5\n",
    "print (\"\\nConfusion matrix:  Custom threshold (for positive) of \" +str(threshold_confusion))\n",
    "y_pred = np.empty((y_scores.shape[0]))\n",
    "for i in range(y_scores.shape[0]):\n",
    "    if y_scores[i]>=threshold_confusion:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "print (confusion)\n",
    "accuracy = 0\n",
    "if float(np.sum(confusion))!=0:\n",
    "    accuracy = float(confusion[0,0]+confusion[1,1])/float(np.sum(confusion))\n",
    "print (\"Global Accuracy: \" +str(accuracy))\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "print (\"Specificity: \" +str(specificity))\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print (\"Sensitivity: \" +str(sensitivity))\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "print (\"Precision: \" +str(precision))\n",
    "\n",
    "#Jaccard similarity index\n",
    "jaccard_index = jaccard_similarity_score(y_true, y_pred, normalize=True)\n",
    "print (\"\\nJaccard similarity score: \" +str(jaccard_index))\n",
    "\n",
    "#F1 score\n",
    "F1_score = f1_score(y_true, y_pred, labels=None, average='binary', sample_weight=None)\n",
    "print (\"\\nF1 score (F-measure): \" +str(F1_score))\n",
    "\n",
    "#Save the results\n",
    "file_perf = open(output_folder+'performances.txt', 'w')\n",
    "file_perf.write(\"Area under the ROC curve: \"+str(AUC_ROC)\n",
    "                + \"\\nArea under Precision-Recall curve: \" +str(AUC_prec_rec)\n",
    "                + \"\\nJaccard similarity score: \" +str(jaccard_index)\n",
    "                + \"\\nF1 score (F-measure): \" +str(F1_score)\n",
    "                +\"\\n\\nConfusion matrix:\"\n",
    "                +str(confusion)\n",
    "                +\"\\nACCURACY: \" +str(accuracy)\n",
    "                +\"\\nSENSITIVITY: \" +str(sensitivity)\n",
    "                +\"\\nSPECIFICITY: \" +str(specificity)\n",
    "                +\"\\nPRECISION: \" +str(precision)\n",
    "                )\n",
    "file_perf.close()\n",
    "\n",
    "# Sample results\n",
    "fig,ax = plt.subplots(5, 3, figsize=[15,15])\n",
    "all_ind = [1, 100, 200, 253, 193] # random samples\n",
    "all_ind = np.array(all_ind)\n",
    "for idx in range(5):\n",
    "    ax[idx, 0].imshow(np.uint8(np.squeeze(te_data[all_ind[idx]])))\n",
    "    ax[idx, 1].imshow(np.squeeze(te_mask[all_ind[idx]]), cmap='gray')  \n",
    "    ax[idx, 2].imshow(np.squeeze(Estimated_lung[all_ind[idx]]), cmap='gray')  \n",
    "        \n",
    "plt.savefig('sample_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import models as M\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard,ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "import pickle\n",
    "   \n",
    "####################################  Load Data #####################################\n",
    "folder = './processed_data/'\n",
    "tr_data    = np.load(folder+'data_train.npy')\n",
    "tr_mask    = np.load(folder+'Train_maska.npy')\n",
    "tr_data    = np.expand_dims(tr_data, axis=3)\n",
    "tr_mask    = np.expand_dims(tr_mask, axis=3)\n",
    "\n",
    "print('Dataset loaded')\n",
    "\n",
    "tr_data   = tr_data /255.\n",
    "\n",
    "print('dataset Normalized')\n",
    "\n",
    "# Build model\n",
    "model = M.BCDU_net_D3(input_size = (512,512,1))\n",
    "model.summary()\n",
    "\n",
    "print('Training')\n",
    "batch_size = 2\n",
    "nb_epoch   = 50\n",
    "\n",
    "\n",
    "mcp_save = ModelCheckpoint('weight_lung', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "history = model.fit(tr_data,tr_mask,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_split=0.2, callbacks=[mcp_save, reduce_lr_loss] )\n",
    "  \n",
    "print('Trained model saved')\n",
    "with open('hist_lung', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Reza_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6456\\3211923144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mReza_functions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Reza_functions'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import Reza_functions as RF\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define Train data and mask\n",
    "Data_train   = []\n",
    "Mask_train   = []\n",
    "Maska_train  = []\n",
    "FOV_train    = []\n",
    "\n",
    "idx_count =1\n",
    "Tr_add = '3d_images'\n",
    "\n",
    "Tr_list = glob.glob(Tr_add+'/*.gz')\n",
    "\n",
    "for idx in range(len(Tr_list)):\n",
    "    b = Tr_list[idx]\n",
    "    a = b[len(Tr_add)+1:len(Tr_add)+4]\n",
    "    if a=='IMG':\n",
    "       print(idx_count)\n",
    "       a = b[len(Tr_add)+5:len(b)]\n",
    "       add = (Tr_add+'/MASK_' + a) \n",
    "       vol = nib.load(Tr_list[idx])\n",
    "       seg = nib.load(add)\n",
    "       # Get the axials images and corresponding masks\n",
    "       vol_ims, lung, around_lung, FOV = RF.return_axials(vol, seg)          \n",
    "       segmentation  = seg.get_data()\n",
    "       # Insert samples to the Train data, which has the segmentation label\n",
    "       for idx in range(vol.shape[0]):\n",
    "           if ~( np.sum(np.sum(np.sum(segmentation[idx, :, :]))) == 0): \n",
    "               Data_train.append(vol_ims [idx, :, :])\n",
    "               Mask_train.append(lung[idx, :, :])\n",
    "               Maska_train.append(around_lung[idx, :, :])               \n",
    "               FOV_train.append(FOV[idx, :, :])               \n",
    "       idx_count += 1\n",
    "        \n",
    "Data_train  = np.array(Data_train)\n",
    "Mask_train  = np.array(Mask_train)\n",
    "Maska_train = np.array(Maska_train)\n",
    "FOV_train   = np.array(FOV_train)\n",
    "\n",
    "# We use 70% of the data for training and 30% for test\n",
    "alpha = np.int16(np.floor(Data_train.shape[0]* 0.7))\n",
    "en_d  = Data_train.shape[0]\n",
    "\n",
    "Train_img      = Data_train[0:alpha,:,:]\n",
    "Test_img       = Data_train[alpha:en_d,:,:]\n",
    "\n",
    "Train_mask     = Mask_train[0:alpha,:,:]\n",
    "Test_mask      = Mask_train[alpha:en_d,:,:]\n",
    "\n",
    "Train_maska     = Maska_train[0:alpha,:,:]\n",
    "Test_maska      = Maska_train[alpha:en_d,:,:]\n",
    "\n",
    "FOV_tr     = FOV_train[0:alpha,:,:]\n",
    "FOV_te      = FOV_train[alpha:en_d,:,:]\n",
    "\n",
    "folder = './processed_data/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "np.save(folder+'data_train' , Train_img)\n",
    "np.save(folder+'data_test'  , Test_img)\n",
    "np.save(folder+'mask_train' , Train_mask)\n",
    "np.save(folder+'mask_test'  , Test_mask)\n",
    "\n",
    "np.save(folder+'Train_maska' , Train_maska)\n",
    "np.save(folder+'Test_maska'  , Test_maska)\n",
    "np.save(folder+'FOV_tr'      , FOV_tr)\n",
    "np.save(folder+'FOV_te'      , FOV_te)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610afcfab8d92197fd8fa1dd69c9a0fe3f98f600233dfd0ef802fd8443096641"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
