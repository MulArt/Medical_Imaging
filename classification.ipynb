{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHARGEMENT DES DONNEES (IMAGES) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DCM', 'test', 'train', 'valid']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"Data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"Data\")\n",
    "train_dir = data_dir/'train'\n",
    "valid_dir = data_dir/'valid'\n",
    "test_dir = data_dir/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    normal_cases_dir = train_dir/'normal'\n",
    "    adenocarcinoma_cases_dir = train_dir/'adenocarcinoma'\n",
    "\n",
    "    #Listes des images\n",
    "\n",
    "    normal_cases = normal_cases_dir.glob('*.png')\n",
    "    adenocarcinoma_cases = adenocarcinoma_cases_dir.glob('*png')\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "\n",
    "    for img in normal_cases:\n",
    "        train_data.append(img)\n",
    "        train_label.append('normal')\n",
    "\n",
    "    for img in adenocarcinoma_cases:\n",
    "        train_data.append(img)\n",
    "        train_label.append('adenocarcinoma')\n",
    "    \n",
    "    df = pd.DataFrame(train_data)\n",
    "    df.columns=['images']\n",
    "    df['labels']=train_label\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=load_train()\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(train_data['labels'].value_counts().index, train_data['labels'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(2,5,i+1)\n",
    "        img = cv2.imread(str(image_batch[i]))\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        plt.imshow(img)\n",
    "        plt.title(label_batch[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-PROCESS DES DONNEES :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_load(isval=True):\n",
    "    if isval==True:\n",
    "        normal_dir = valid_dir/'normal'\n",
    "        adenocarcinoma_dir = valid_dir/'adenocarcinoma' \n",
    "    else:\n",
    "        normal_dir = test_dir/'normal'\n",
    "        adenocarcinoma_dir = test_dir/'adenocarcinoma'\n",
    "    normal_cases = normal_dir.glob('*.png')\n",
    "    adenocarcinoma_cases = adenocarcinoma_dir.glob('*.png')\n",
    "    data, labels = ([] for x in range(2))\n",
    "    def prepare(case):\n",
    "        for img in case:\n",
    "            img = cv2.imread(str(img))\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "\n",
    "            if img.shape[2] == 1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32)/255.\n",
    "\n",
    "            if case == normal_cases:\n",
    "                label = to_categorical(0, num_classes=2)\n",
    "            else:\n",
    "                label = to_categorical(1, num_classes=2)\n",
    "            \n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "        return data, labels\n",
    "\n",
    "    prepare(normal_cases)\n",
    "\n",
    "    d,l = prepare(adenocarcinoma_cases)\n",
    "    d = np.array(d)\n",
    "    l = np.array(l)\n",
    "\n",
    "    return d,l        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre images test :  174\n",
      "Number images de validation :  36\n"
     ]
    }
   ],
   "source": [
    "val_data, val_labels = prepare_and_load(isval=True)\n",
    "test_data, test_labels = prepare_and_load(isval=False)\n",
    "\n",
    "print('Nombre images test : ', len(test_data))\n",
    "print('Number images de validation : ', len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size): \n",
    "    # nombre total d'échantillons dans les données\n",
    "    n = len(data)\n",
    "    steps = n/batch_size\n",
    "\n",
    "    # création de 2 tableaux pour les groupes de données et labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype = np.float32)\n",
    "    batch_labels = np.zeros((batch_size, 2), dtype = np.float32)\n",
    "\n",
    "    # un autre tableau pour les indices de données en entrée\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    # Initialisation d'un compteur \n",
    "    i = 0\n",
    "    while True: \n",
    "        np.random.shuffle(indices)\n",
    "        # lot suivant\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['images']\n",
    "            label = data.iloc[idx]['labels']\n",
    "            if label=='normal':\n",
    "                label = 0\n",
    "            else :\n",
    "                label = 1\n",
    "            \n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            \n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            orig_img = img.astype(np.float32)/255\n",
    "\n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "            count+= 1\n",
    "\n",
    "            if count == batch_size-1:\n",
    "                break\n",
    "\n",
    "        i+= 1\n",
    "        yield batch_data, batch_labels\n",
    "\n",
    "        if i>=steps:\n",
    "            i=0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELE DE CLASSIFICATION CNN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'entrainements et d'étapes de validations : 20 et 36\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape = (224, 224, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten()) #converti les maps en vecteurs 1D\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "nb_epochs = 3\n",
    "\n",
    "# obtenir un générateur de données d'entrainement\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# défini le nombre d'étapes d'entrainement\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Nombre d'entrainements et d'étapes de validations : {} et {}\".format(nb_train_steps, len(val_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiba\\AppData\\Local\\Temp\\ipykernel_19164\\1711196156.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 15s 650ms/step - loss: 0.8251 - accuracy: 0.7125 - val_loss: 0.3957 - val_accuracy: 0.8611\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 12s 589ms/step - loss: 0.2801 - accuracy: 0.8813 - val_loss: 0.1930 - val_accuracy: 0.9444\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 12s 597ms/step - loss: 0.0832 - accuracy: 0.9625 - val_loss: 0.0871 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'rmsprop',\n",
    "                metrics =['accuracy'])\n",
    "\n",
    "# fit le modèle\n",
    "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "                                validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFERT D'APPRENTISSAGE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model(num_classes=None): \n",
    "\n",
    "    model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "    x = Dense(1024, activation='relu')(model.layers[-4].output)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(model.input,x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_conv = vgg16_model(2)\n",
    "\n",
    "for layer in vgg_conv.layers[:-10]: # freeze tous les layers sauf les 10 derniers\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiba\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\thiba\\AppData\\Local\\Temp\\ipykernel_19164\\3137498313.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = vgg_conv.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 104s 5s/step - loss: 0.4105 - accuracy: 0.6812 - val_loss: 0.2319 - val_accuracy: 0.9722\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 104s 5s/step - loss: 0.1246 - accuracy: 0.8844 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.0511 - accuracy: 0.9375 - val_loss: 0.0464 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "vgg_conv.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "\n",
    "# on fit le modèle\n",
    "history = vgg_conv.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "                                    validation_data=(val_data,val_labels),\n",
    "                                    class_weight={0:1.0, 1:0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 39s 3s/step - loss: 0.0861 - accuracy: 0.9655\n",
      "Perte et Précision :  0.08609364181756973 & 0.9655172228813171\n"
     ]
    }
   ],
   "source": [
    "loss , acc = vgg_conv.evaluate(test_data, test_labels, batch_size = 16)\n",
    "print('Perte et Précision : ',loss,'&',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION DES PERFORMANCES DU MODELE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 36s 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95        54\n",
      "           1       0.99      0.96      0.97       120\n",
      "\n",
      "    accuracy                           0.97       174\n",
      "   macro avg       0.95      0.97      0.96       174\n",
      "weighted avg       0.97      0.97      0.97       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions \n",
    "pred = vgg_conv.predict(test_data, batch_size=16)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "#label original\n",
    "labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matrice de confusion\n",
    "cm = confusion_matrix(labels, pred)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels=['Normal', 'Adenocarcinoma'], yticklabels=['Normal', 'Adenocarcinoma'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a879106b2b18878579d9347381e22ada575de5d14ca86f191130cfab0f92ae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
