{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des bibliothèques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm as tq\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# ablumentations for easy image augmentation for input as well as output\n",
    "import albumentations as albu\n",
    "# from albumentations import torch as AT\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding function for reproducibility\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def resize_it(x):\n",
    "    if x.shape != (350, 525):\n",
    "        x = cv2.resize(x, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Dataset class\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame = None,\n",
    "        datatype: str = \"train\",\n",
    "        img_ids: np.array = None,\n",
    "        transforms=albu.Compose([albu.HorizontalFlip()]), #, AT.ToTensor()\n",
    "    ):\n",
    "        self.df = df\n",
    "        if datatype != \"test\":\n",
    "            self.data_folder = f\"{img_paths}/train_images_525/train_images_525\"\n",
    "        else:\n",
    "            self.data_folder = f\"{img_paths}/test_images_525/test_images_525\"\n",
    "        self.img_ids = img_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.img_ids[idx]\n",
    "        mask = make_mask(self.df, image_name)\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = np.transpose(augmented[\"image\"], [2, 0, 1])\n",
    "        mask = np.transpose(augmented[\"mask\"], [2, 0, 1])\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']\n",
    "\n",
    "def draw_convex_hull(mask, mode='convex'):\n",
    "    \n",
    "    img = np.zeros(mask.shape)\n",
    "    contours, hier = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        if mode=='rect': # simple rectangle\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "        if mode=='convex': # minimum convex hull\n",
    "            hull = cv2.convexHull(c)\n",
    "            cv2.drawContours(img, [hull], 0, (255, 255, 255),-1)\n",
    "        else: # minimum area rectangle\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img, [box], 0, (255, 255, 255),-1)\n",
    "    return img/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(x, folder: str = \"train_images_525/train_images_525\"):\n",
    "    \"\"\"\n",
    "    Return image based on image name and folder.\n",
    "    \"\"\"\n",
    "    data_folder = f\"{img_paths}/{folder}\"\n",
    "    image_path = os.path.join(data_folder, x)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle: str = \"\", shape: tuple = (1400, 2100)):\n",
    "    \"\"\"\n",
    "    Decode rle encoded mask.\n",
    "\n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order=\"F\")\n",
    "\n",
    "\n",
    "def make_mask(df: pd.DataFrame, image_name: str = \"img.jpg\", shape: tuple = (350, 525)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    df = df[df[\"im_id\"] == image_name]\n",
    "    for idx, im_name in enumerate(df[\"im_id\"].values):\n",
    "        for classidx, classid in enumerate([\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]):\n",
    "            mask = cv2.imread(\n",
    "                \"../input/understanding-clouds-resized/train_masks_525/train_masks_525/\"\n",
    "                + classid\n",
    "                + im_name\n",
    "            )\n",
    "            if mask is None:\n",
    "                continue\n",
    "            if mask[:, :, 0].shape != (350, 525):\n",
    "                mask = cv2.resize(mask, (525, 350))\n",
    "            masks[:, :, classidx] = mask[:, :, 0]\n",
    "    masks = masks / 255\n",
    "    return masks\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Convert image or mask.\n",
    "    \"\"\"\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "\n",
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \"\"\"\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    \"\"\"\n",
    "    Plot image and masks.\n",
    "    If two pairs of images and masks are passes, show both.\n",
    "    \"\"\"\n",
    "    fontsize = 14\n",
    "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}\n",
    "\n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        for i in range(4):\n",
    "            ax[i + 1].imshow(mask[:, :, i])\n",
    "            ax[i + 1].set_title(f\"Mask {class_dict[i]}\", fontsize=fontsize)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[0, i + 1].imshow(original_mask[:, :, i])\n",
    "            ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(image)\n",
    "        ax[1, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[1, i + 1].imshow(mask[:, :, i])\n",
    "            ax[1, i + 1].set_title(\n",
    "                f\"Transformed mask {class_dict[i]}\", fontsize=fontsize\n",
    "            )\n",
    "\n",
    "\n",
    "def visualize_with_raw(\n",
    "    image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot image and masks.\n",
    "    If two pairs of images and masks are passes, show both.\n",
    "    \"\"\"\n",
    "    fontsize = 14\n",
    "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}\n",
    "\n",
    "    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n",
    "\n",
    "    ax[0, 0].imshow(original_image)\n",
    "    ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[0, i + 1].imshow(original_mask[:, :, i])\n",
    "        ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "    ax[1, 0].imshow(raw_image)\n",
    "    ax[1, 0].set_title(\"Original image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[1, i + 1].imshow(raw_mask[:, :, i])\n",
    "        ax[1, i + 1].set_title(f\"Raw predicted mask {class_dict[i]}\", fontsize=fontsize)\n",
    "\n",
    "    ax[2, 0].imshow(image)\n",
    "    ax[2, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[2, i + 1].imshow(mask[:, :, i])\n",
    "        ax[2, i + 1].set_title(\n",
    "            f\"Predicted mask with processing {class_dict[i]}\", fontsize=fontsize\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_with_augmentation(image, mask, augment):\n",
    "    \"\"\"\n",
    "    Wrapper for `visualize` function.\n",
    "    \"\"\"\n",
    "    augmented = augment(image=image, mask=mask)\n",
    "    image_flipped = augmented[\"image\"]\n",
    "    mask_flipped = augmented[\"mask\"]\n",
    "    visualize(image_flipped, mask_flipped, original_image=image, original_mask=mask)\n",
    "\n",
    "\n",
    "# sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    This is slightly different from other kernels as we draw convex hull here itself.\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    # don't remember where I saw it\n",
    "    mask = (cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1])\n",
    "    mask = draw_convex_hull(mask.astype(np.uint8))\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = component == c\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num\n",
    "\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.ShiftScaleRotate(\n",
    "            scale_limit=0.5,\n",
    "            rotate_limit=0,\n",
    "            shift_limit=0.1,\n",
    "            p=0.5,\n",
    "            border_mode=0\n",
    "        ),\n",
    "        albu.GridDistortion(p=0.5),\n",
    "        albu.Resize(320, 640),\n",
    "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(320, 640),\n",
    "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "\n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function\n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "\n",
    "def dice(img1, img2):\n",
    "    img1 = np.asarray(img1).astype(np.bool)\n",
    "    img2 = np.asarray(img2).astype(np.bool)\n",
    "\n",
    "    intersection = np.logical_and(img1, img2)\n",
    "\n",
    "    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())\n",
    "\n",
    "def dice_no_threshold(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reference:\n",
    "    https://catalyst-team.github.io/catalyst/_modules/catalyst/dl/utils/criterion/dice.html\n",
    "    \"\"\"\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '../input/understanding_cloud_organization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thiba\\OneDrive - Fondation EPF\\Personal computer\\Desktop\\EPF\\Majeure santé\\semestre 7\\Projet_IMIA\\Medical_Imaging\\segmentation_2.ipynb Cellule 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/OneDrive%20-%20Fondation%20EPF/Personal%20computer/Desktop/EPF/Majeure%20sant%C3%A9/semestre%207/Projet_IMIA/Medical_Imaging/segmentation_2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m N_FOLDS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m# in K-fold\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/OneDrive%20-%20Fondation%20EPF/Personal%20computer/Desktop/EPF/Majeure%20sant%C3%A9/semestre%207/Projet_IMIA/Medical_Imaging/segmentation_2.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m seed_everything(SEED)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thiba/OneDrive%20-%20Fondation%20EPF/Personal%20computer/Desktop/EPF/Majeure%20sant%C3%A9/semestre%207/Projet_IMIA/Medical_Imaging/segmentation_2.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m os\u001b[39m.\u001b[39;49mlistdir(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '../input/understanding_cloud_organization'"
     ]
    }
   ],
   "source": [
    "path = \"../input/understanding_cloud_organization\"\n",
    "img_paths = \"../input/understanding-clouds-resized\"\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "SEED = 42\n",
    "MODEL_NO = 0 # in K-fold\n",
    "N_FOLDS = 10 # in K-fold\n",
    "seed_everything(SEED)\n",
    "os.listdir(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a879106b2b18878579d9347381e22ada575de5d14ca86f191130cfab0f92ae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
